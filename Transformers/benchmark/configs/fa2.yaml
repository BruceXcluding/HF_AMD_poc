defaults:
  - _base_
  - _self_

experiment_name: pytorch_llama_fa2-batch(${benchmark.input_shapes.batch_size})

backend:
  use_flash_attention_2: true
